{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['SPARK_HOME'] = r'C:\\Users\\Marcos\\Documents\\Spark'\n",
    "os.environ['PYSPARK_DRIVER_PYTHON'] = 'jupyter'\n",
    "os.environ['PYSPARK_DRIVER_PYTHON_OPTS'] = 'lab'\n",
    "os.environ['PYSPARK_PYTHON'] = 'python'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.types import StructType, StructField, StringType, IntegerType, DoubleType, DateType"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = SparkSession.builder.appName('Create-DataFrame').getOrCreate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read CSV with no schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_path = 'data/walmart-sales-dataset-of-45stores.csv'\n",
    "df = spark.read.csv(csv_path, header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- Store: string (nullable = true)\n",
      " |-- Date: string (nullable = true)\n",
      " |-- Weekly_Sales: string (nullable = true)\n",
      " |-- Holiday_Flag: string (nullable = true)\n",
      " |-- Temperature: string (nullable = true)\n",
      " |-- Fuel_Price: string (nullable = true)\n",
      " |-- CPI: string (nullable = true)\n",
      " |-- Unemployment: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+----------+------------+------------+-----------+----------+-----------+------------+\n",
      "|Store|      Date|Weekly_Sales|Holiday_Flag|Temperature|Fuel_Price|        CPI|Unemployment|\n",
      "+-----+----------+------------+------------+-----------+----------+-----------+------------+\n",
      "|    1|05-02-2010|   1643690.9|           0|      42.31|     2.572|211.0963582|       8.106|\n",
      "|    1|12-02-2010|  1641957.44|           1|      38.51|     2.548|211.2421698|       8.106|\n",
      "|    1|19-02-2010|  1611968.17|           0|      39.93|     2.514|211.2891429|       8.106|\n",
      "|    1|26-02-2010|  1409727.59|           0|      46.63|     2.561|211.3196429|       8.106|\n",
      "|    1|05-03-2010|  1554806.68|           0|       46.5|     2.625|211.3501429|       8.106|\n",
      "+-----+----------+------------+------------+-----------+----------+-----------+------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read CSV and defining a schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "schema = StructType([\n",
    "    StructField(name='Store', dataType=IntegerType(), nullable=True),\n",
    "    StructField(name='Date', dataType=StringType(), nullable=True),\n",
    "    StructField(name='Weekly_Sales', dataType=DoubleType(), nullable=True),\n",
    "    StructField(name='Holiday_Flag', dataType=IntegerType(), nullable=True),\n",
    "    StructField(name='Temperature', dataType=DoubleType(), nullable=True),    \n",
    "    StructField(name='Fuel_Price', dataType=DoubleType(), nullable=True),    \n",
    "    StructField(name='CPI', dataType=DoubleType(), nullable=True),\n",
    "    StructField(name='Unemployment', dataType=DoubleType(), nullable=True)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = spark.read.csv(csv_path, header=True, schema=schema)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- Store: integer (nullable = true)\n",
      " |-- Date: string (nullable = true)\n",
      " |-- Weekly_Sales: double (nullable = true)\n",
      " |-- Holiday_Flag: integer (nullable = true)\n",
      " |-- Temperature: double (nullable = true)\n",
      " |-- Fuel_Price: double (nullable = true)\n",
      " |-- CPI: double (nullable = true)\n",
      " |-- Unemployment: double (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+----------+------------+------------+-----------+----------+-----------+------------+\n",
      "|Store|      Date|Weekly_Sales|Holiday_Flag|Temperature|Fuel_Price|        CPI|Unemployment|\n",
      "+-----+----------+------------+------------+-----------+----------+-----------+------------+\n",
      "|    1|05-02-2010|   1643690.9|           0|      42.31|     2.572|211.0963582|       8.106|\n",
      "|    1|12-02-2010|  1641957.44|           1|      38.51|     2.548|211.2421698|       8.106|\n",
      "|    1|19-02-2010|  1611968.17|           0|      39.93|     2.514|211.2891429|       8.106|\n",
      "|    1|26-02-2010|  1409727.59|           0|      46.63|     2.561|211.3196429|       8.106|\n",
      "|    1|05-03-2010|  1554806.68|           0|       46.5|     2.625|211.3501429|       8.106|\n",
      "+-----+----------+------------+------------+-----------+----------+-----------+------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read CSV with inferSchema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = spark.read.csv(csv_path, header=True, inferSchema=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- Store: integer (nullable = true)\n",
      " |-- Date: string (nullable = true)\n",
      " |-- Weekly_Sales: double (nullable = true)\n",
      " |-- Holiday_Flag: integer (nullable = true)\n",
      " |-- Temperature: double (nullable = true)\n",
      " |-- Fuel_Price: double (nullable = true)\n",
      " |-- CPI: double (nullable = true)\n",
      " |-- Unemployment: double (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+----------+------------+------------+-----------+----------+-----------+------------+\n",
      "|Store|      Date|Weekly_Sales|Holiday_Flag|Temperature|Fuel_Price|        CPI|Unemployment|\n",
      "+-----+----------+------------+------------+-----------+----------+-----------+------------+\n",
      "|    1|05-02-2010|   1643690.9|           0|      42.31|     2.572|211.0963582|       8.106|\n",
      "|    1|12-02-2010|  1641957.44|           1|      38.51|     2.548|211.2421698|       8.106|\n",
      "|    1|19-02-2010|  1611968.17|           0|      39.93|     2.514|211.2891429|       8.106|\n",
      "|    1|26-02-2010|  1409727.59|           0|      46.63|     2.561|211.3196429|       8.106|\n",
      "|    1|05-03-2010|  1554806.68|           0|       46.5|     2.625|211.3501429|       8.106|\n",
      "+-----+----------+------------+------------+-----------+----------+-----------+------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read JSON"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "json_path = 'data/store.json'\n",
    "df = spark.read.json(json_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- category: string (nullable = true)\n",
      " |-- id: long (nullable = true)\n",
      " |-- name: string (nullable = true)\n",
      " |-- price: double (nullable = true)\n",
      " |-- quantity: long (nullable = true)\n",
      "\n",
      "+---------------+---+--------------------+------+--------+\n",
      "|       category| id|                name| price|quantity|\n",
      "+---------------+---+--------------------+------+--------+\n",
      "|    Electronics|  1|           iPhone 12|899.99|      10|\n",
      "|       Clothing|  2|     Nike Air Max 90|119.99|      25|\n",
      "|Home Appliances|  3|KitchenAid Stand ...|299.99|       5|\n",
      "|          Books|  4|    The Great Gatsby| 12.99|      50|\n",
      "|         Beauty|  5|L'Oreal Paris Mas...|  9.99|     100|\n",
      "+---------------+---+--------------------+------+--------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.printSchema()\n",
    "df.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "json_path_mult = 'data/store-multiline.json'\n",
    "df = spark.read.json(json_path_mult, multiLine=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- CPI: double (nullable = true)\n",
      " |-- Date: string (nullable = true)\n",
      " |-- Fuel_Price: double (nullable = true)\n",
      " |-- Holiday_Flag: long (nullable = true)\n",
      " |-- Store: long (nullable = true)\n",
      " |-- Temperature: double (nullable = true)\n",
      " |-- Unemployment: double (nullable = true)\n",
      " |-- Weekly_Sales: double (nullable = true)\n",
      "\n",
      "+-----------+----------+----------+------------+-----+-----------+------------+------------+\n",
      "|        CPI|      Date|Fuel_Price|Holiday_Flag|Store|Temperature|Unemployment|Weekly_Sales|\n",
      "+-----------+----------+----------+------------+-----+-----------+------------+------------+\n",
      "|211.0963582|05-02-2010|     2.572|           0|    1|      42.31|       8.106|   1643690.9|\n",
      "|211.2421698|12-02-2010|     2.548|           1|    1|      38.51|       8.106|  1641957.44|\n",
      "|211.2891429|19-02-2010|     2.514|           0|    1|      39.93|       8.106|  1611968.17|\n",
      "|211.3196429|26-02-2010|     2.561|           0|    1|      46.63|       8.106|  1409727.59|\n",
      "|211.3501429|05-03-2010|     2.625|           0|    1|       46.5|       8.106|  1554806.68|\n",
      "+-----------+----------+----------+------------+-----+-----------+------------+------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.printSchema()\n",
    "df.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Parquet data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parquet_path = 'data/store.parquet'\n",
    "df.write.parquet(parquet_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = spark.read.parquet(parquet_path)\n",
    "df.printSchema()\n",
    "df.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.stop()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
